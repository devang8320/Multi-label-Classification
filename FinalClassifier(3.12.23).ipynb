{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import joblib  # Use 'joblib' for saving the best estimator\n",
    "from statistics import stdev\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the data\n",
    "X = pd.read_csv('PCA_R3_Noramlaized_ZScore.csv')\n",
    "y = pd.read_csv('labels_train.csv')\n",
    "\n",
    "# Assuming y is a DataFrame and you have multiple columns representing different outputs\n",
    "# If not, modify the following line based on your actual data structure\n",
    "y_train = y.values  # Convert DataFrame to a NumPy array\n",
    "\n",
    "# Compute class weights for each label\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train.flatten()), y=y_train.flatten())\n",
    "\n",
    "# Create a dictionary with class labels as keys and corresponding class weights as values\n",
    "class_weight_dict = dict(zip(np.unique(y_train.flatten()), class_weights))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size=0.95, random_state=42)\n",
    "\n",
    "# Define individual classifiers # updated class imbalance condition\n",
    "svm_classifier = SVC(probability=True, random_state=42, class_weight=class_weight_dict)\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42, class_weight=class_weight_dict)\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('svm', svm_classifier),\n",
    "        ('decision_tree', decision_tree_classifier)\n",
    "    ],\n",
    "    voting='soft'  # Use 'soft' voting for probability averaging\n",
    ")\n",
    "\n",
    "# Create a MultiOutputClassifier for the VotingClassifier\n",
    "multioutput_voting_classifier = MultiOutputClassifier(voting_classifier)\n",
    "\n",
    "# Define parameter grids for hyperparameter tuning\n",
    "param_grid_decision_tree = {\n",
    "    'estimator__decision_tree__max_depth': [3, 5, 7, 10],  # Adjust other hyperparameters as needed\n",
    "}\n",
    "\n",
    "# Create GridSearchCV for hyperparameter tuning for each classifier\n",
    "grid_search_decision_tree = GridSearchCV(\n",
    "    estimator=multioutput_voting_classifier,\n",
    "    param_grid=param_grid_decision_tree,\n",
    "    scoring=make_scorer(f1_score, average='micro'),\n",
    "    cv=5,\n",
    "    # n_jobs=-1  # Use all available processors for parallel processing\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCVs to the training data\n",
    "grid_search_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Save the best-tuned MultiOutputClassifier from GridSearchCVs using joblib\n",
    "best_multioutput_classifier_decision_tree = grid_search_decision_tree.best_estimator_\n",
    "joblib.dump(best_multioutput_classifier_decision_tree, 'best_model_decision_tree_with_std.joblib')\n",
    "\n",
    "# Make predictions using the best-tuned classifiers\n",
    "best_predictions_decision_tree = best_multioutput_classifier_decision_tree.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score for each class using the best-tuned classifiers\n",
    "best_f1_scores_decision_tree = f1_score(y_test, best_predictions_decision_tree, average=None)\n",
    "\n",
    "# Calculate the average F1 score across all classes using the best-tuned classifiers\n",
    "best_average_f1_score_decision_tree = f1_score(y_test, best_predictions_decision_tree, average='micro')\n",
    "\n",
    "# Print or use the F1 scores from the best-tuned classifiers\n",
    "print(\"Best Decision Tree F1 scores for each class:\", best_f1_scores_decision_tree)\n",
    "print(\"Best Decision Tree Average F1 score:\", best_average_f1_score_decision_tree)\n",
    "\n",
    "# Calculate standard deviation of F1 scores for each class\n",
    "f1_scores_std = stdev(best_f1_scores_decision_tree)\n",
    "print(\"Standard Deviation of F1 scores for each class:\", f1_scores_std)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV for each classifier\n",
    "print(\"Best Decision Tree Hyperparameters:\", grid_search_decision_tree.best_params_)\n",
    "\n",
    "# # Export the results to a CSV file\n",
    "# results_df = pd.DataFrame({\n",
    "#     'Class': range(1, len(best_f1_scores_decision_tree) + 1),\n",
    "#     'F1 Score': best_f1_scores_decision_tree\n",
    "# })\n",
    "#deviation \n",
    "accuracy_on_dt = cross_val_score(best_multioutput_classifier_decision_tree, X_train, y_train, cv=5,scoring='f1_micro')\n",
    "print(\"Accuracy is on training is:\", accuracy_on_dt)\n",
    "print(f'The standard deviation across the five accuracy measurements using best_multioutput_classifier_decision_tree : {accuracy_on_dt.std():.3f}')\n",
    "print(f'The average accuracy across all five folds using best_multioutput_classifier_decision_tree: {accuracy_on_dt.mean():.3f}')\n",
    "\n",
    "# results_df.to_csv('decision_tree_results.csv', index=False)\n",
    "\n",
    "# Make predictions on the entire dataset (X) using the trained model\n",
    "predicted_labels = best_multioutput_classifier_decision_tree.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with the predicted labels\n",
    "predicted_labels_df = pd.DataFrame(data=predicted_labels, columns=y.columns)  # Assuming y has column names\n",
    "\n",
    "# Save the DataFrame with predicted labels to a CSV file\n",
    "predicted_labels_df.to_csv('predicted_labels_Final.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"Predicted labels have been saved to predicted_labels_Final.csv.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
